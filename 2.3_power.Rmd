---
title: "Анализ мощности"
author: Марина Варфоломеева
output:
  ioslides_presentation:
    widescreen: true
    css: assets/my_styles.css
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6, digits = 3)
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE)
```

```{r libs, echo=FALSE}
library(ggplot2)
library(grid)
library(gridExtra) # to rescale legend
```

## Мы рассмотрим

  - Мощность статистического теста
  - Способы оценки величины эффекта
  - *A priori* анализ мощности
  - Использование симуляций для анализа мощности
  - Как влиять на мощность тестов

# Мощность статистического теста


```{r power_data, echo = FALSE, cache=TRUE, purl=FALSE}
# Power plot using ggplot2
# reworked after
# http://rpsychologist.com/creating-a-typical-textbook-illustration-of-statistical-power-using-either-ggplot-or-base-graphics/
# TODO: needs serious improvements

#### Custom themes ####
# theme_bw with only x axis
theme_bw_x <- function (base_size = 12, base_family = "")
{
  require(ggplot2)
  theme_bw(base_size = base_size, base_family = base_family) %+replace%
    theme(panel.border = element_blank(),
          axis.line.x = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.line.y = element_blank(),
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank(),
          axis.title.y = element_blank(),
          legend.key = element_blank(),
          legend.key.size = unit(3, "lines"),
          legend.text = element_text(size = 24, hjust = 0.5))
}

# theme_bw without axes and with larger legend
theme_bw_noxy <- function (base_size = 12, base_family = "")
{
  require(ggplot2)
  theme_bw(base_size = base_size, base_family = base_family) %+replace%
    theme(panel.border = element_blank(), axis.line.x = element_line(colour = "black"),
          panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          axis.line = element_blank(), axis.text = element_blank(),
          axis.ticks = element_blank(), axis.title = element_blank(),
          legend.key = element_blank(),
          legend.key.size = unit(3, "lines"),
          legend.text = element_text(size = 24, hjust = 0.5))
}

#### Data for power curves ####

generate_power_data <- function(m1 = 0, sd1 = 7, m2 = 3.5, sd2 = 7, alpha = 0.05, h.type = "equal"){
  # set length of tails
  min1 <- m1-sd1*4
  max1 <- m1+sd1*4
  min2 <- m2-sd2*4
  max2 <- m2+sd2*4
  # create a sequence for x axis including z.crit
  x <- seq(min(min1,min2), max(max1, max2), .01)
  # compute critical value

  switch(h.type,
         greater={
           z.crit <- qnorm(1-alpha, m1, sd1)
           z.critm <- m1 - abs(m1 - z.crit)
         },
         less={
           z.crit <- qnorm(1-alpha, m1, sd1)
           z.critm <- m1 - abs(m1 - z.crit)
         },
         equal={
           z.crit <- qnorm(1-(alpha/2), m1, sd1)
           z.critm <- m1 - abs(m1 - z.crit)
         }
  )
  x[length(x)+1] <- z.crit
  x[length(x)+1] <- z.critm
  x <- sort(x)

  # generate normal distributions
  y1 <- dnorm(x, m1, sd1)
  y2 <- dnorm(x, m2, sd2)
  # combine to data frame
  df1 <- data.frame(x = x, y = y1)
  df2 <- data.frame(x = x, y = y2)
  # compute intervals for polygons
  outside.l <- x <= z.critm
  inside <- (x >= z.critm) & (x <= z.crit)
  outside.r <- x >= z.crit

  switch(h.type,
         greater={
           # Alpha polygon
           if(m1 < m2){
             alph <- data.frame(x = x[outside.r], y = pmin(y1[outside.r], y2[outside.r]))
           } else {
             alph <- data.frame(x = x[outside.r], y = pmax(y1[outside.r], y2[outside.r]))
           }
           alph$y[alph$x == z.crit] <- 0
           # Beta polygon one-tailed
           bet <- data.frame(x = x[outside.l | inside], y = y2[outside.l | inside])
           bet$y[bet$x == z.crit] <- 0
           bet$y[bet$x == z.critm] <- 0
           # power polygon; 1-beta, one-tailed
           pwrd <- data.frame(x = x[outside.r], y = y2[outside.r])
           pwrd$y[pwrd$x == z.crit] <- 0
           alph$id <- 3
           bet$id <- 2
           pwrd$id <- 1
           alph$obj <- 3
           bet$obj <- 2
           pwrd$obj <- 1
           # combine data frames
           poly <- rbind(alph, bet, pwrd)
           poly$id <- factor(poly$id,  labels = c("power","beta","alpha"))
         },
         less={
           # Alpha polygon
           if(m1 < m2){
             alph <- data.frame(x = x[outside.l], y = pmax(y1[outside.l], y2[outside.l]))
           } else{
             alph <- data.frame(x = x[outside.l], y = pmin(y1[outside.l], y2[outside.l]))
           }
           alph$y[alph$x == z.critm] <- 0
           # Beta polygon one-tailed
           bet <- data.frame(x = x[outside.r | inside], y = y2[outside.r | inside])
           bet$y[bet$x == z.crit] <- 0
           bet$y[bet$x == z.critm] <- 0
           # power polygon; 1-beta, one-tailed
           pwrd <- data.frame(x = x[outside.l], y = y2[outside.l])
           pwrd$y[pwrd$x == z.critm] <- 0
           alph$id <- 3
           bet$id <- 2
           pwrd$id <- 1
           alph$obj <- 3
           bet$obj <- 2
           pwrd$obj <- 1
           # combine data frames
           poly <- rbind(alph, bet, pwrd)
           poly$id <- factor(poly$id,  labels = c("power","beta","alpha"))
         },
         equal={
           # alph polygon
           if(m1 < m2){
             alph.r <- data.frame(x = x[outside.r], y = pmin(y1[outside.r], y2[outside.r]))
             alph.l <- data.frame(x = x[outside.l], y = pmax(y1[outside.l], y2[outside.l]))
           } else {
             alph.r <- data.frame(x = x[outside.r], y = pmax(y1[outside.r], y2[outside.r]))
             alph.l <- data.frame(x = x[outside.l], y = pmin(y1[outside.l], y2[outside.l]))
           }
           alph.r$y[alph.r$x == z.crit] <- 0
           alph.l$y[alph.l$x == z.critm] <- 0
           # beta polygon, two-tailed
           bet <- data.frame(x = x[inside], y = y2[inside])
           bet$y[bet$x == z.crit] <- 0
           bet$y[bet$x == z.critm] <- 0
           # two power polygons, two-tailed
           pwrd.l <- data.frame(x = x[outside.l], y = y2[outside.l])
           pwrd.l$y[pwrd.l$x == z.critm] <- 0
           pwrd.r <-data.frame(x = x[outside.r], y = y2[outside.r])
           pwrd.r$y[pwrd.r$x == z.crit] <- 0
           alph.l$id <- 3
           alph.l$obj <- 5
           alph.r$id <- 3
           alph.r$obj <- 4
           bet$id <- 2
           bet$obj <-3
           pwrd.l$id <- 1
           pwrd.l$obj <- 2
           pwrd.r$id <- 1
           pwrd.r$obj <- 1
           # combine data frames
           poly <- rbind(alph.l, alph.r, bet, pwrd.l, pwrd.r)
           poly$id <- factor(poly$id,  labels = c("power","beta","alpha"))
           poly$obj <- factor(poly$obj,  labels = c("powerr","powerl", "beta", "alphar", "alphal"))
         }
  )
  return(list(df1 = df1, df2 = df2, poly = poly, m1 = m1, m2 = m2, h.type = h.type, z.crit = z.crit, z.critm = z.critm))
}

pwr_plot <- function(pwrd, alph = TRUE, bet = TRUE, power = TRUE, ann = TRUE){
  require(ggplot2)
  # initialise filter for the data
  filter <- vector(length = length(pwrd$poly$id))
  # possible values for the scale
  category <- vector()
  lbls <- vector()
  if(alph){
    filter <- pwrd$poly$id == "alpha"
    category <- c(category, "alpha")
    lbls <- c(lbls, bquote(alpha))
  }
  if(bet){
    filter <- filter | pwrd$poly$id == "beta"
    category <- c(category, "beta")
    lbls <- c(lbls, bquote(beta))
  }
  if(power){
    filter <- filter | pwrd$poly$id == "power"
    category <- c(category, "power")
    lbls <- c(lbls, bquote(1 - beta))
  }
  # define colours by type of polygon
  cols <- c("alpha" = "#d95f02", "beta" = "#7570b3", "power" = "#1b9e77")
  if(any(alph, bet, power)){
  p <- ggplot() +
    geom_line(data = pwrd$df1, aes(x, y, linetype = "H0", group = NULL, fill = NULL)) +
    geom_line(data = pwrd$df2, aes(x, y, linetype = "Ha", group = NULL, fill = NULL)) +
    geom_polygon(data = pwrd$poly[filter, ], aes(x, y, fill = id, group = obj), alpha = 0.4) +
    scale_linetype_discrete(name = "Гипотезы") +
    scale_fill_manual(values = cols, limits = category, name = "Вероятности", labels = lbls)
  } else {
    p <- ggplot() +
      geom_line(data = pwrd$df1, aes(x, y, linetype = "H0", group = NULL, fill = NULL)) +
      geom_line(data = pwrd$df2, aes(x, y, linetype = "Ha", group = NULL, fill = NULL)) +
      scale_linetype_discrete(name = "Гипотезы")
  }
  return(p)
}

dat <- generate_power_data(m1 = 0, m2 = 5, sd1 = 10, sd2 = 10, h.type = "equal")
```


## Типы ошибок при проверке гипотез

| 	|H0 == TRUE |	H0 == FALSE |
|-----|-----|-----|
| Отклонить H0 	| Ошибка I рода </br> <span class="orange">&alpha;</span> | 	Верно </br> 1 - &alpha; |
| Сохранить H0 	| Верно </br> | Ошибка II рода </br> <span class= "blue">&beta;</span> |

<br /><br /><br />

```{r power_beta, echo = FALSE, fig.height=2.5, purl=FALSE}
pwr_plot(pwrd = dat, alph = T, bet = T, power = F) +
  guides(fill = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme_bw_noxy()
```


## Мощность статистического теста

| 	|H0 == TRUE |	H0 == FALSE |
|-----|-----|-----|
| Отклонить H0 	| Ошибка I рода </br> <span class="orange">&alpha;</span> | 	Верно </br> 1 - &alpha; |
| Сохранить H0 	| Верно </br> <span class= "green">1 - &beta;</span> | Ошибка II рода </br> <span class= "blue">&beta;</span> |

### Мощность статистического теста --- 
вероятность найти различия там, где они есть $Power = 1 - \beta$

```{r power_all, echo = FALSE, fig.height=2.5, purl=FALSE}
pwr_plot(pwrd = dat, alph = T, bet = T, power = T) +
  guides(fill = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme_bw_noxy()
```

## Анализ мощности

- Какой нужен объем выборки, чтобы найти различия?
- Какой величины различия мы можем найти при определенном объеме выборки?

# Величина эффекта

## Величина эффекта

$$\frac{\bar \mu_1 - \bar \mu_2}{\sigma}$$

## Величина эффекта

$$\frac{\bar \mu_1 - \bar \mu_2}{\sigma}$$

- $\sigma$ --- среднеквадратичное стандартное отклонение

$d = \frac {|\bar x_1 - \bar x_2|} { \sqrt {\frac {s_1^2 + s_2^2 } {2} }}$

## Величина эффекта

$$\frac{\bar \mu_1 - \bar \mu_2}{\sigma}$$

- $\sigma$ --- среднеквадратичное стандартное отклонение

$d = \frac {|\bar x_1 - \bar x_2|} { \sqrt {\frac {s_1^2 + s_2^2 } {2} }}$

- $\sigma$ --- обобщенное стандартное отклонение

$d = \frac {|\bar x _{1} - \bar x _{2}|} { \sqrt {\frac {(n_{1} - 1) s_1^2 + (n_{2} - 1) s_{2}^2 }  {n_{1} + n_{2} - 2} } }$


## Как оценить ожидаемую величину эффекта?

$$\frac{\bar \mu_1 - \bar \mu_2}{\sigma}$$

Варианты:

- Пилотные исследования
- Литература
- Общебиологические знания
- Технические требования

## Условные уровни величины эффекта 

Сильные, умеренные и слабые эффекты (Cohen, 1982)

```{r }
library(pwr)
cohen.ES(test = "t", size = "large")
```

## Задача

Рассчитайте величину умеренных и слабых эффектов для t-критерия при помощи функции `cohen.ES()`

## Решение

```{r purl=FALSE}
# умеренный
cohen.ES(test = "t", size = "medium")
# слабый
cohen.ES(test = "t")
```

## Задача

Исследователи хотят проверить, что у крыс на богатой жирами диете ген "гормона голода" лептина будет даун-регулироваться в 5 раз.

Т.е. ожидаемая разница логарифмов экспрессии между опытом и контролем будет примерно $log2(1) - log2(5) = -2.32$

Стандартное отклонение этих различий по пилотным данным 1.2

Рассчитайте величину эффекта

Скажите, это будет слабый или сильный эффект?

## Решение

```{r purl=FALSE}
abs(-2.32) / 1.2
```

# Расчет величины эффекта по данным пилотного исследования

## Величина эффекта по данным пилотного исследования

Представьте себе, что у нас есть результаты пилотного исследования. Мы хотим знать, различается ли уровень клеточной активности у пациентов в зависимости от того, наступила ли ремиссия. (Данные из кн. Freeman 1987).

```{r}
library(readxl)
rem <- read_excel(path = "data/remission.xlsx", sheet = 1)
head(rem)
```

Это данные о больных раком:

- `LI` --- мера клеточной активности
- `r` --- индикатор того наступила ли ремиссия (1 --- да, 0 --- нет)

## Убедимся, что данные открылись правильно

```{r}
str(rem)

rem$r <- factor(rem$r, levels = c(0, 1), labels = c("no", "yes"))
```



```{r}
## Пропущенные значения
colSums(is.na(rem))
## Объем выборки
table(rem$r)
```

## Задача

Визуализируйте при помощи бокс-плотов различия клеточной активности в двух группах пациентов.

Используйте геом `geom_boxplot()`

Обозначьте группу при помощи заливки.

Подпишите оси при помощи элемента `labs()`

## Решение

```{r gg-cell-boxplot, purl=FALSE}
library(ggplot2)
ggplot(rem, aes(x = r, y = LI)) + 
  geom_boxplot(aes(fill = r)) + 
  labs(x = "Remission", y = "Cell activity", fill = "Remission")
```

## Давайте оценим величину эффекта

```{r}
library(effsize)
effect <- cohen.d(rem$LI, rem$r)
effect
```

## Задача

Посмотрите на структуру объекта `effect`  при помощи функции `str()` и добудьте из него средствами R значение величины эффекта

## Решение

```{r purl=FALSE}
str(effect)
effect$estimate
```

# Анализ мощности в R


## Анализ мощности t-критерия в R

Давайте рассчитаем, какой будет нужен объем выборки, чтобы показать различия между группами с вероятностью 0.8 (т.е. чтобы мощность теста была 80%)

```{r}
library(pwr)
pwr.t.test(n = NULL, d = effect$estimate, power = 0.8, 
           sig.level = 0.05, type = "two.sample", 
           alternative = "two.sided")
```

## Задача

Экстрагируйте из результатов `pwr.t.test()` величину объема выборки


## Решение

```{r purl=FALSE}
R1 <- pwr.t.test(n = NULL, d = effect$estimate, power = 0.8,
                 sig.level = 0.05, type = "two.sample", 
                 alternative = "two.sided")
str(R1)
R1$n
```

Округляем в большую сторону

```{r purl=FALSE}
ceiling(R1$n)
```


## Задача

А если группы будут разного размера?

Пациентов с ремиссией всего 5.

Сколько нужно обследовать пациентов без ремиссии, чтобы обнаружить различия клеточной активности между группами?

Используйте функцию `pwr.t2n.test`

## Решение

```{r purl=FALSE}
R2 <- pwr.t2n.test(n1 = 5, n2 = NULL, d = effect$estimate, 
                   power = 0.8, sig.level = 0.05, 
                   alternative = "two.sided")
ceiling(R2$n2)
```

## Другой пример

Данные анализа мочи. В некоторых пробах обнаружены кристаллы оксалата кальция. (Данные из сборника датасетов Andrews Herzberg 1985)

Представим, что это данные пилотного исследования. 

```{r}
ur <- read_excel(path = "data/urine.xlsx", sheet = 1)
head(ur)
```

- `r` --- индикатор присутствия кристаллов оксалата кальция
- `calc` --- концентрация кальция

## Убедимся, что данные открылись правильно

```{r}
str(ur)

ur$r <- factor(ur$r, levels = c(0, 1), 
               labels = c("absent", "present"))
```

## 

```{r}
## Пропущенные значения
colSums(is.na(ur))
## Объем выборки
table(ur$r)
```

## Задача

Постройте гистограмму распределения концентрации кальция.
Заливкой обозначьте присутствие кристаллов оксалата кальция в пробе.

## Решение

```{r gg-urine-hist, purl=FALSE}
ggplot(ur, aes(x = calc, fill = r)) + 
  geom_histogram(binwidth = 1, position = "dodge") + 
  labs(x = "Calcium, mmol/l", y = "N", fill = "Crystals of calcium oxalate")
```

## Задача

Сколько нужно анализов, чтобы показать, что содержание кальция в этих пробах достоверно отличается при уровне значимости $\alpha = 0.001$?

- При равном объеме выборок
- Если будет только 16 проб с кристаллами оксалата кальция

## Решение

```{r purl=FALSE}
effect_ur <- cohen.d(ur$calc, ur$r)
R3 <- pwr.t.test(n = NULL, d = abs(effect_ur$estimate),
                 power = 0.8, sig.level = 0.001, 
                 type = "two.sample", alternative = "two.sided")
ceiling(R3$n)
R4 <- pwr.t2n.test(n1 = 16, n2 = NULL, d = effect_ur$estimate, 
                   power = 0.8, sig.level = 0.001, 
                   alternative = "two.sided")
ceiling(R4$n2)
```

# Анализ мощности t-критерия при помощи симуляции

## Анализ мощности t-критерия при помощи симуляции

При помощи простой симуляции можно проверить, будет ли достаточно 24 наблюдений в группе

Сначала готовим данные

```{r}
# средние значения из пилотного исследования
mu <- tapply(X = ur$calc, INDEX = ur$r, FUN = mean)

# обобщенное стандартное отклонение sigma в пилотном исследовании
ns <- table(ur$r)
var <- tapply(X = ur$calc, INDEX = ur$r, FUN = var)
sigma <- sqrt(((ns[1] - 1) * var[1] + (ns[2] - 1) * var[2])/(length(ur$r) - 2))

n <- 24 # проверяемое значение объема выборки
reps <- 1000 # число повторов в симуляции
```

## ВАРИАНТ 1 - Используем цикл

```{r}
pvals <- rep(NA, reps) # Место для результата
set.seed(42) # зерно генератора случайных чисел

# в цикле  многократно симулируем данные 
for (i in 1:reps){
  # генерируем две случайные выборки 
  # из нормального распределения
  x1 <- rnorm(n, mu[1], sigma)
  x2 <- rnorm(n, mu[2], sigma)
  # сравниваем их средние значения t-критерием
  t_res <- t.test(x = x1, y = x2)
  # добываем уровень значимости
  pvals[i] <- t_res$p.value
}
# Доля уровней значимости меньше критического уровня (здесь p < 0.001)
mean(pvals < 0.001)
```

## ВАРИАНТ 2 - Используем `replicate()`

```{r}
# функция, генерирующая одну симуляцию
# n - объем выборки
my_sim <- function(n) {
  x1 <- rnorm(n, mu[1], sigma)
  x2 <- rnorm(n, mu[2], sigma)
  t_res <- t.test(x = x1, y = x2)
  return(t_res$p.value)
}
# my_sim(24) # пример употребления - одна симуляция

# Повторяем симуляцию 1000 раз
set.seed(42)
pvals <- replicate(1000, my_sim(24))
mean(pvals < 0.001)
```

## Как проверить несколько возможных объемов выборки?

Вариант 2 легче масштабируется.

Достаточно дописать еще одну функцию, и мы сможем оценить мощность теста при разных объемах выборки.

```{r}
# функция, возвращающая долю симуляций с p < 0.001
# x - объем выборки
my_sim_range <- function(x){
  pvals <- replicate(1000, my_sim(x))
  pw <- mean(pvals < 0.001)
  return(pw)
}
set.seed(42)
sapply(X = 20:25, FUN = my_sim_range)
```

## Задание

По итогам предыдущей симуляции постройте кривую зависимости мощности от объема выборки (от 5 до 35)

## Решение

```{r gg-power-urine, purl=FALSE}
set.seed(42)
sim <- sapply(X = 5:35, FUN = my_sim_range)

pwr_dat <- data.frame(N = 5:35, Power = sim)
ggplot(pwr_dat, aes(x = N, y = Power)) + 
  geom_point(colour = "green3") + 
  geom_line(aes(group = 1), colour = "green3") +
  geom_hline(yintercept = 0.8, linetype = "dashed")
```


## Задание

При помощи симуляций проведите анализ мощности для данных о клеточной активности у больных раком

Постройте кривую зависимости мощности теста от объема выборки

## Решение: подготовка

```{r purl=FALSE}
# средние значения из пилотного исследования
mu <- tapply(X = rem$LI, INDEX = rem$r, FUN = mean)

# обобщенное стандартное отклонение sigma в пилотном исследовании
ns <- table(rem$r)
var <- tapply(X = rem$LI, INDEX = rem$r, FUN = var)
sigma <- sqrt(((ns[1] - 1) * var[1] + (ns[2] - 1) * var[2])/(length(ur$r) - 2))

reps <- 1000 # число повторов в симуляции
```

## Решение: симуляция

```{r purl=FALSE}
# функция, генерирующая одну симуляцию
my_sim <- function(n) {
  x1 <- rnorm(n, mu[1], sigma)
  x2 <- rnorm(n, mu[2], sigma)
  t_res <- t.test(x = x1, y = x2)
  return(t_res$p.value)
}

# функция, возвращающая долю симуляций со значением p меньше критического
my_sim_range <- function(x){
  pvals <- replicate(1000, my_sim(x))
  fraction <- mean(pvals < 0.001)
  return(fraction)
}

set.seed(42)
sim <- sapply(X = 5:15, FUN = my_sim_range)

```

## Решение: график зависимости мощности от объема выборки

```{r purl=FALSE}
pwr_dat <- data.frame(N = 5:15, Power = sim)
ggplot(pwr_dat, aes(x = N, y = Power)) + 
  geom_point(colour = "steelblue") + 
  geom_line(aes(group = 1), colour = "steelblue") +
  geom_hline(yintercept = 0.8, linetype = "dashed")
```

# Как влиять на мощность теста?

## Мощность зависит


- от объема выборки
- от величины эффекта
- от уровня значимости

## Чем больше объем выборки—тем больше мощность


```{r pwr_vs_n, echo = FALSE, cache = TRUE, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 5}
# Plots of power vs. sample size etc.
# Modified after http://imdevsoftware.wordpress.com/2013/01/17/255/

# Need pwr, reshape2, ggplot2 packages
gen_pwr_vs_n <- function(d = c(0.2, 0.5, 0.8), a = c(0.05, 0.01), n = 150){
  if(!require(pwr)){install.packages("pwr");library("pwr")}
  # t-TEST
  #---------------------------------
  n <- 1:n
  t.test.power.effect<-
    as.data.frame(do.call("cbind", lapply(1:length(d),function(i){
    sapply(1:length(a),function(k){
      sapply(1:length(n), function(j){
        #       paste(d[i], n[j], a[k])
        power.t.test(n = n[j],d = d[i],sig.level = a[k],power = NULL,
                     type = "two.sample")$power
      })
    })
  })))
  t.test.power.effect[is.na(t.test.power.effect)]<-0 # some powers couldn't be calculated, set these to zero
  # melt the data
  if(!require(reshape2)){install.packages("reshape2");library("reshape2")}
  measured <- length(d)*length(a)
  t.test.power.effect <- melt(t.test.power.effect, measure.vars = 1:measured)
  # fill the levels of n, a, and d
  nms <- expand.grid(size = n, sig.level = a, effect = d)
  t.test.power.effect <- cbind(t.test.power.effect, nms)
  # do-not need variable column
  t.test.power.effect <- t.test.power.effect[, -1]
  return(t.test.power.effect)
}

dat <-gen_pwr_vs_n(n = 150)
# factors
dat$sig.level <- factor(dat$sig.level, levels = c(0.01, 0.05),
                        labels = c("p = 0.01", "p = 0.05"))
dat$effect <- factor(dat$effect, levels = c(0.2, 0.3, 0.5, 0.8),
                     labels = c("d = 0.2", "d = 0.3", "d = 0.5", "d = 0.8"))

# Power increases as the sample size increases
# plot power vs n at d = 0.5, p = 0.01
pwr.size <-
  ggplot(data = dat[(dat$effect == "d = 0.5" & dat$sig.level == "p = 0.05"), ],
         aes(x = size, y = value, color = sig.level)) +
  geom_line(size = 1.5) +
  scale_colour_discrete(name = "Уровень\nзначимости") +
  labs(x = "Объем выборки", y = "Мощность") +
  ggtitle("t-тест, d = 0.5") +
  theme_minimal(base_size = 18) +
  theme(legend.key = element_blank(),
        axis.line = element_line(colour = "black"))
pwr.size
```

## Чем больше уровень значимости—тем больше мощность

```{r cache = TRUE, dependson='pwr_vs_n', echo = FALSE, warning = FALSE, fig.width = 10, fig.height = 5}
# Power increases as the signifficance level increases
#   plot power vs n at d = 0.5, add linetype = sig.level (p = 0.01, p = 0.05)
pwr_size_apha <- ggplot(data = dat[dat$effect == "d = 0.5", ],
                        aes(x = size, y = value, color = sig.level)) +
  geom_line(size = 1.5) +
  scale_colour_discrete(name = "Уровень\nзначимости",
                        limits = c("p = 0.05", "p = 0.01")) +
  labs(x = "Объем выборки", y = "Мощность") +
  ggtitle("t-тест, d = 0.5") +
  theme_minimal(base_size = 18) +
  theme(legend.key = element_blank(),
        axis.line = element_line(colour = "black"))
pwr_size_apha
```

## Чем больше величина различий—тем больше мощность

```{r cache = TRUE, dependson='pwr_vs_n', echo = FALSE, warning = FALSE, fig.width = 10, fig.height = 5}
# Power increases as effect size increases
#   plot power vs n at
# add linetype = sig.level (p = 0.01, p = 0.05)
# add facets for d = 0.2, d = 0.5, d = 0.8
pwr_size_alpha_d <- ggplot(data = dat, aes(x = size, y = value, color = sig.level)) +
    geom_line(size = 1.5) + facet_wrap(~effect) +
  scale_colour_discrete(name = "Уровень\nзначимости",
                        limits = c("p = 0.05", "p = 0.01")) +
  labs(x = "Объем выборки", y = "Мощность") +
  ggtitle("t-тест") +
  theme_minimal(base_size = 18) +
  theme(legend.key = element_blank(),
        axis.line = element_line(colour = "black"))
pwr_size_alpha_d
```

## Скажите

Какие из факторов, влияющих на мощность теста, мы __не можем__ контролировать?

> - Мы не можем контролировать внешние факторы
    - величину эффекта ($ES$)
    - фоновую изменчивость ($\sigma^2$)

Каким образом можно повлиять на мощность теста?

> - Мощность теста можно регулировать, если
    - изменить число повторностей
    - выбрать другой уровень значимости ($\alpha$)
    - определиться, какие эффекты действительно важны ($ES$)

## Take home messages

>- Способность выявлять различия зависит
    - от объема выборки,
    - от уровня значимости
    - от величины эффекта

## Дополнительные ресурсы

- Quinn, Keough, 2002, pp. 164-170
- [OpenIntro Statistics](http://www.openintro.org)
