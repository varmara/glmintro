---
title: "Тестирование статистических гипотез"
author: "Юта Тамберг, Марина Варфоломеева"
subtitle: ""
output:
  ioslides_presentation:
    css: assets/my_styles.css
    widescreen: yes
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6, digits = 3)
library(knitr)
library(ggplot2)
library(gridExtra)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE)
```

# ЧАСТЬ 1. Tеория

## Сравнение выборок

<div class="columns-2">


<center>
![](images/2.2_lizards1.png)
</center>

<center>
![](images/2.2_lizards2.png)
</center>

<div/>

Различия между выборками не всегда видны невооружённым глазом.

## Гипотезы: нулевая и альтернативная

Первый шаг в сравнении – формулировка нулевой гипотезы.

Положение H0 привелигерованное: именно ее мы тестируем, принимаем или отвергаем.

Чаще всего она формулируется как **отсутствие различий** между сравниваемыми объектами. Например: ящерицы из двух популяций одинаково крупные.

Вместе с нулевой гипотезой рождается на свет и альтернативная гипотеза.

В общем виде, она формулируется как **присутствие различий** и включает все частные случаи, например "размеры ящериц из двух популяций неодинаковы".

## Гипотезы: нулевая и альтернативная

Решение о том, принять или отвергнуть H0 мы принимаем после статистического теста. Но результат теста не тождественен реальному состоянию дел - он не скажет, верна ли H0, только укажет, как с ней поступить.

Вне зависимости от нас, реальность может находиться в одном из двух состояний:  H0 верна, ящерицы одинаковы, либо H0 неверна, и ящерицы различаются.

Таким образом, возможно четыре исхода теста.

В мире где ящерицы одинаковы мы можем 

- принять H0 (и это будет верное решение),
- либо отвергнуть ее (и это будет ошибка). 

Аналогично, в мире где ящерицы различаются, мы можем 

- принять H0 (что ошибочно),
- либо отвергнуть ее (что верно).

## Верные и неверные решения


| 	|H0 == TRUE |	H0 == FALSE |
|:-----:|:-----:|:-----:|
| Отклонить H0 | Ошибка I рода с вероятностью <span class="orange">&alpha;</span></br>Ложно-положительный результат | 	Верно |
| Сохранить H0 | Верно | Ошибка II рода с вероятностью <span class= "blue">&beta;</span> </br> Ложно-отрицательный результат |


## Верные и неверные решения

**Ошибка I рода: нашли то, чего нет**

**Ошибка II рода: пропустили то, что было**


```{r power_data, echo = FALSE, cache=TRUE}
# Power plot using ggplot2
# reworked after
# http://rpsychologist.com/creating-a-typical-textbook-illustration-of-statistical-power-using-either-ggplot-or-base-graphics/
# TODO: needs serious improvements

#### Custom themes ####
# theme_bw with only x axis
theme_bw_x <- function (base_size = 12, base_family = "")
{
  require(ggplot2)
  theme_bw(base_size = base_size, base_family = base_family) %+replace%
    theme(panel.border = element_blank(),
          axis.line.x = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.line.y = element_blank(),
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank(),
          axis.title.y = element_blank(),
          legend.key = element_blank(),
          legend.key.size = unit(3, "lines"),
          legend.text = element_text(size = 24, hjust = 0.5))
}

# theme_bw without axes and with larger legend
theme_bw_noxy <- function (base_size = 12, base_family = "")
{
  require(ggplot2)
  theme_bw(base_size = base_size, base_family = base_family) %+replace%
    theme(panel.border = element_blank(), axis.line.x = element_line(colour = "black"),
          panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          axis.line = element_blank(), axis.text = element_blank(),
          axis.ticks = element_blank(), axis.title = element_blank(),
          legend.key = element_blank(),
          legend.key.size = unit(3, "lines"),
          legend.text = element_text(size = 24, hjust = 0.5))
}

#### Data for power curves ####

generate_power_data <- function(m1 = 0, sd1 = 7, m2 = 3.5, sd2 = 7, alpha = 0.05, h.type = "equal"){
  # set length of tails
  min1 <- m1-sd1*4
  max1 <- m1+sd1*4
  min2 <- m2-sd2*4
  max2 <- m2+sd2*4
  # create a sequence for x axis including z.crit
  x <- seq(min(min1,min2), max(max1, max2), .01)
  # compute critical value

  switch(h.type,
         greater={
           z.crit <- qnorm(1-alpha, m1, sd1)
           z.critm <- m1 - abs(m1 - z.crit)
         },
         less={
           z.crit <- qnorm(1-alpha, m1, sd1)
           z.critm <- m1 - abs(m1 - z.crit)
         },
         equal={
           z.crit <- qnorm(1-(alpha/2), m1, sd1)
           z.critm <- m1 - abs(m1 - z.crit)
         }
  )
  x[length(x)+1] <- z.crit
  x[length(x)+1] <- z.critm
  x <- sort(x)

  # generate normal distributions
  y1 <- dnorm(x, m1, sd1)
  y2 <- dnorm(x, m2, sd2)
  # combine to data frame
  df1 <- data.frame(x = x, y = y1)
  df2 <- data.frame(x = x, y = y2)
  # compute intervals for polygons
  outside.l <- x <= z.critm
  inside <- (x >= z.critm) & (x <= z.crit)
  outside.r <- x >= z.crit

  switch(h.type,
         greater={
           # Alpha polygon
           if(m1 < m2){
             alph <- data.frame(x = x[outside.r], y = pmin(y1[outside.r], y2[outside.r]))
           } else {
             alph <- data.frame(x = x[outside.r], y = pmax(y1[outside.r], y2[outside.r]))
           }
           alph$y[alph$x == z.crit] <- 0
           # Beta polygon one-tailed
           bet <- data.frame(x = x[outside.l | inside], y = y2[outside.l | inside])
           bet$y[bet$x == z.crit] <- 0
           bet$y[bet$x == z.critm] <- 0
           # power polygon; 1-beta, one-tailed
           pwrd <- data.frame(x = x[outside.r], y = y2[outside.r])
           pwrd$y[pwrd$x == z.crit] <- 0
           alph$id <- 3
           bet$id <- 2
           pwrd$id <- 1
           alph$obj <- 3
           bet$obj <- 2
           pwrd$obj <- 1
           # combine data frames
           poly <- rbind(alph, bet, pwrd)
           poly$id <- factor(poly$id,  labels = c("power","beta","alpha"))
         },
         less={
           # Alpha polygon
           if(m1 < m2){
             alph <- data.frame(x = x[outside.l], y = pmax(y1[outside.l], y2[outside.l]))
           } else{
             alph <- data.frame(x = x[outside.l], y = pmin(y1[outside.l], y2[outside.l]))
           }
           alph$y[alph$x == z.critm] <- 0
           # Beta polygon one-tailed
           bet <- data.frame(x = x[outside.r | inside], y = y2[outside.r | inside])
           bet$y[bet$x == z.crit] <- 0
           bet$y[bet$x == z.critm] <- 0
           # power polygon; 1-beta, one-tailed
           pwrd <- data.frame(x = x[outside.l], y = y2[outside.l])
           pwrd$y[pwrd$x == z.critm] <- 0
           alph$id <- 3
           bet$id <- 2
           pwrd$id <- 1
           alph$obj <- 3
           bet$obj <- 2
           pwrd$obj <- 1
           # combine data frames
           poly <- rbind(alph, bet, pwrd)
           poly$id <- factor(poly$id,  labels = c("power","beta","alpha"))
         },
         equal={
           # alph polygon
           if(m1 < m2){
             alph.r <- data.frame(x = x[outside.r], y = pmin(y1[outside.r], y2[outside.r]))
             alph.l <- data.frame(x = x[outside.l], y = pmax(y1[outside.l], y2[outside.l]))
           } else {
             alph.r <- data.frame(x = x[outside.r], y = pmax(y1[outside.r], y2[outside.r]))
             alph.l <- data.frame(x = x[outside.l], y = pmin(y1[outside.l], y2[outside.l]))
           }
           alph.r$y[alph.r$x == z.crit] <- 0
           alph.l$y[alph.l$x == z.critm] <- 0
           # beta polygon, two-tailed
           bet <- data.frame(x = x[inside], y = y2[inside])
           bet$y[bet$x == z.crit] <- 0
           bet$y[bet$x == z.critm] <- 0
           # two power polygons, two-tailed
           pwrd.l <- data.frame(x = x[outside.l], y = y2[outside.l])
           pwrd.l$y[pwrd.l$x == z.critm] <- 0
           pwrd.r <-data.frame(x = x[outside.r], y = y2[outside.r])
           pwrd.r$y[pwrd.r$x == z.crit] <- 0
           alph.l$id <- 3
           alph.l$obj <- 5
           alph.r$id <- 3
           alph.r$obj <- 4
           bet$id <- 2
           bet$obj <-3
           pwrd.l$id <- 1
           pwrd.l$obj <- 2
           pwrd.r$id <- 1
           pwrd.r$obj <- 1
           # combine data frames
           poly <- rbind(alph.l, alph.r, bet, pwrd.l, pwrd.r)
           poly$id <- factor(poly$id,  labels = c("power","beta","alpha"))
           poly$obj <- factor(poly$obj,  labels = c("powerr","powerl", "beta", "alphar", "alphal"))
         }
  )
  return(list(df1 = df1, df2 = df2, poly = poly, m1 = m1, m2 = m2, h.type = h.type, z.crit = z.crit, z.critm = z.critm))
}

pwr_plot <- function(pwrd, alph = TRUE, bet = TRUE, power = TRUE, ann = TRUE){
  require(ggplot2)
  # initialise filter for the data
  filter <- vector(length = length(pwrd$poly$id))
  # possible values for the scale
  category <- vector()
  lbls <- vector()
  if(alph){
    filter <- pwrd$poly$id == "alpha"
    category <- c(category, "alpha")
    lbls <- c(lbls, bquote(alpha))
  }
  if(bet){
    filter <- filter | pwrd$poly$id == "beta"
    category <- c(category, "beta")
    lbls <- c(lbls, bquote(beta))
  }
  if(power){
    filter <- filter | pwrd$poly$id == "power"
    category <- c(category, "power")
    lbls <- c(lbls, bquote(1 - beta))
  }
  # define colours by type of polygon
  cols <- c("alpha" = "#d95f02", "beta" = "#7570b3", "power" = "#1b9e77")
  if(any(alph, bet, power)){
  p <- ggplot() +
    geom_line(data = pwrd$df1, aes(x, y, linetype = "H0", group = NULL, fill = NULL)) +
    geom_line(data = pwrd$df2, aes(x, y, linetype = "Ha", group = NULL, fill = NULL)) +
    geom_polygon(data = pwrd$poly[filter, ], aes(x, y, fill = id, group = obj), alpha = 0.4) +
    scale_linetype_discrete(name = "Гипотезы") +
    scale_fill_manual(values = cols, limits = category, name = "Вероятности", labels = lbls)
  } else {
    p <- ggplot() +
      geom_line(data = pwrd$df1, aes(x, y, linetype = "H0", group = NULL, fill = NULL)) +
      geom_line(data = pwrd$df2, aes(x, y, linetype = "Ha", group = NULL, fill = NULL)) +
      scale_linetype_discrete(name = "Гипотезы")
  }
  return(p)
}

dat <- generate_power_data(m1 = 0, m2 = 5, sd1 = 10, sd2 = 10, h.type = "equal")
```


```{r power_beta, purl=FALSE, echo = FALSE, fig.height=4.5}
pwr_plot(pwrd = dat, alph = T, bet = T, power = F) +
  guides(fill = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme_bw_noxy()
```


## Ошибки

Вероятность ошибки I рода мы задаем сами --- это уровень значимости теста, $\alpha$. Это та вероятность, меньше которой мы отказываемся верить в справедливость H0.

Ошибка второго рода обычно скрыта. Но ее можно уменьшить вслепую, например увеличив объем выборки.

```{r power_beta2, purl=FALSE, echo = FALSE, fig.height=4}
pwr_plot(pwrd = dat, alph = T, bet = T, power = F) +
  guides(fill = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme_bw_noxy()
```


## Как принять решение?

### Статистические таблицы
Принцип прост -- мы вычисляем **эмпирическое** значение тестовой статистики, и сравниваем его с **критическим** значением этой же статистики из таблицы.

Т.е. мы сравниваем тестовую статистику с тестовой статистикой: t-критерий с t-критерием, $\chi^2$ с $\chi^2$.

### P-value

Принятие решения на основании p-value стало возможным когда стали доступны большие вычислительные мощности.

P-value отражает вероятность обнаружить тот уровень различий между выборками который мы видим, при условии что H0 верна.

Если р велико, мы решаем что выборки принципиально одинаковы, если мало - что выборки принципиально различаются.

Принимая решение на основании p-value мы сравниваем ее с уровнем значимости $\alpha$, т.е. сравниваем вероятность с вероятностью.

## P-value. Ещё раз, другими словами

Допустим, мы сравнили выборки и получили р = 0.03

P-value = 0.03 не значит, что H0 верна с вероятностью 3%!

P-value = 0.03 значит, что в мире, где выборки одинаковы а H0 верна, шанс получить результат который мы получили составляет 3%.

Уже мы сами решаем, кажется ли нам такая вероятность приемлимой.


# ЧАСТЬ 2. В сердце статистического теста

## Шаг назад. Cтандартизация 

Из эмпирического распределения *X* cоздадим распределение *Z*, где каждое значение $x_i$ будет заменено на $z_i$. 

1. Выполним центрирование. Для этого заменим значения переменной на девиаты: $x_i - \bar{x}$

2. Нормируем разброс. Для этого разделим девиаты на стандартное отклонение выборки.

$$z_i=\frac{x_i - \bar{x}}{SD}$$


## После стандартизации всегда:
<div class="columns-2">

```{r echo=FALSE, purl=FALSE, fig.height=5.95, fig.width=5.5}
Xi <- rnorm(n = 10000, mean = 50, sd = 7)
Mu <- mean(Xi)
SD <- sd(Xi)
Zi <- (Xi - Mu) / SD
Z <- data.frame(Xi, Zi)

gg_sample <- ggplot(data = Z, aes(x = Xi)) + geom_histogram(binwidth = 2, fill = "steelblue", color = "black") + labs(title = "Normal Distribution, \nmu = 50, sd = 7") + geom_vline(xintercept = mean(Xi), colour = "red", size = 1)

gg_z <- ggplot(data = Z, aes(x = Zi)) + geom_histogram(binwidth = 0.3, fill = "steelblue", color = "black") + labs(title = "Standard Normal Distribution, \nmu = 0, sd = 1") + geom_vline(xintercept = mean(Zi), colour = "red", size = 1)

grid.arrange(gg_sample, gg_z, ncol = 1)
```

- среднее $\mu = 0$

- стандартное отклонение $\sigma = 1$

</div>

## Операции с распределениями

Давайте познакомимся с тремя полезными функциями для работы с распределениями: `r, q, p`

### r = random number generation.

С помощью этой функции можно смоделировать взятие выборки из генеральной совокупности с заданными параметрами.

Например: `rnorm(1000, mean = 20, sd = 2)` сгенерирует выборку в 1000 случайных значений из нормального распределения.


### q = quantile function.

С ее помощью можно получить квантиль (точнее персентиль) - то значение переменной, которое отсекает заданную часть распределения.

Например: `qnorm(0.5, mean = 20, sd = 2)` вернет среднюю, т.к. ровно 50% значений в нормальном распределении $< \mu$

`qnorm(0.025, mean = 20, sd = 2)` вернет то значение X, которое делит распределение на куски в 2.5% и 97.5%, т.е. 2.5% всех значений будут меньше, а 97.5% - больше него.

## Задание

С помощью функции `qnorm` получите 5-number summary для распределения с параметрами $\mu$ = 3 и $\sigma$ = 5

## Решение

Для 5-number summary нам нужны минимальное и максимальное значение, медиана, I и III квантили.

Создадим вектор 

```{r}
five_numbers <- c(0, 0.25, 0.5, 0.75, 1)
```

и передадим его функции `qnorm`

```{r}
qnorm(five_numbers, 3, 5)
```

## Операции с распределениями

### p = probability distribution function

С ее помощью можно рассчитать вероятность того, что случайная величина, взятая из данного распределения, окажется меньше заданного нами значения.

Эта операция принципиально обратна тому, что делает `q`.

Например: `pnorm(20, mean = 20, sd = 2)` вернет вероятность 0.5, или 50%, поскольку мы передали ей в качестве аргумента среднюю

Эта функция работает кумулятивно:

```{r}
round(pnorm(c(0, 15, 20, 25, 40), 20, 2), 3)
```

## t-статистика

$$t=\frac{d}{SE_d}$$

- $d=\bar{x_1} - \bar{x_2}$ - это разность между двумя средними значениями  

- $SE_d$ - Общее среднеквадратичное отклонение разности двух средних

$$SE_d = \sqrt{\frac{sd_1^2(n_1-1) +sd_2^2(n_2-1)}{n_1+n_2-2}(\frac{1}{n_1} + \frac{1}{n_2})}$$

Если $n_1 = n_2$, то формула существенно упрощается

<small>$$SE_d = \sqrt{\frac {sd_1^2} {n_1} + \frac {sd_2^2} {n_2}}$$</small>

Таким образом, t-распределение это стандартизованное распределение разностей двух средних значений из одной генеральной совокупности

## t-распределение

Распределение t-статистики описывает заковыристая функция. Нам нужно знать про нее один важный факт: форма распределения зависит от единственного параметра $df$ - числа степеней свободы.

$$df = n_1 + n_2 - 2$$

Давайте посмотрим, как выглядят распределения с разными df:

```{r, echo=FALSE, purl=FALSE}
t <- seq(-4.5,4.5,0.01)
t2 <- rep(seq(-4.5,4.5,0.01), 2)
df <- c(rep(3,length(t)), rep(300,length(t)))
pt <- c(dt(t, 3), dt(t, 300))
t_dist <- data.frame(t2, df, pt)
t_dist$df <- as.factor(t_dist$df)
gg_t_dfs <- ggplot(data = t_dist, aes(x=t2, y=pt, group=df, color=df)) + geom_line(size=1.5) + geom_vline(xintercept = 0) + xlab("t-statistic") + ylab("Probability")
gg_t_dfs
```


# ЧАСТЬ 3. Применение t-теста

## Пример t-теста

Давайте выполним t-тест и решим, как нам поступить с нулевой гипотезой (для этого нам пригодятся операции `qt` и `pt`)

Для начала создадим две выборки длин ящериц из популяций Берлина и Саратова. В этих гипотетических выборках длины распределены нормально, и имеют заведомо отличающимиеся $\mu$

```{r}
# Зерно для генератора случайных чисел для сопоставимости результатов
set.seed(456) 
# Создаем две выборки по 100 из нормального распределения с разными параметрами
Saratov <- rnorm(n = 100, mean = 130, sd = 5)
Berlin <- rnorm(n = 100, mean = 129, sd = 5)
city <- c(rep("B", 100), rep("S", 100))
# Сохраняем выборки в датафрейме для удобства
lizards <- data.frame(city = factor(city),
                        length = c(Berlin, Saratov))


head(lizards)

```

## Построим частотные распределения этих выборок

```{r}
library(ggplot2) # Загрузим библиотеку
theme_set(theme_bw()) # Зададим тему
```

Сконструируем "скелет" графика

```{r height-gg-plot1, warning=FALSE, message=FALSE}
ggplot(lizards, aes(x = length)) + 
  geom_histogram()
```

## Изменим ширину интервалов гистограммы
Здесь ящерицы из разных мест пока еще смешаны.

```{r height-gg-plot2}
ggplot(lizards, aes(x = length)) + 
  geom_histogram(binwidth = 3)
```

## Разделим столбцы гистограммы по признаку city и сохраним в новую переменную

```{r height-gg-plot3}
gg_length <- ggplot(lizards, aes(x = length, fill = city)) + 
    geom_histogram(binwidth = 3, colour = "grey40", position = "dodge")
gg_length
```

## Добавим подписи осей и заголовок

```{r height-gg-plot5}
gg_length + 
  labs(x = "Length (cm)", 
       y = "Count", 
       title ="Length distribution of lizards", 
       fill = "City")
```

### Наш график готов!

## Выполним t-тест

```{r}
t_lizards <- t.test(data = lizards, length ~ city)
# length ~ city показывает, что значения переменной
# length сгруппированы по признаку city
# Порядок записи важен!
t_lizards
```

## Основные результаты

`t_lizards` это комплексный объект, который можно изучить с помощью функции `str()`

Нас интересуют две переменные: значение тестовой t-статистики 

```{r}
t_value_lizards <- t_lizards$statistic
t_value_lizards
```

и итоговое p-value

```{r}
p_value_lizards <- t_lizards$p.value
p_value_lizards
```


## Достоверны ли различия? Смотрим в "таблицу"

Рассчитаем "табличное" значение t-критерия с помощью функции `qt()`

- так как критерий двухсторонний, мы должны разбить 5% на два кусочка по 2.5%, т.е. `p = c(0.025, 0.975)`
- число степенией свободы $n_1 + n_2 - 2$ равно `100 + 100 - 2 = 198`

Подставим эти аргументы:

```{r}
qt(p = c(0.025, 0.975), 198)
```

Теперь с этими критическими значениями можно сравнить эмпирический результат:

```{r}
t_value_lizards
```

## Достоверны ли различия? Сравниваем вероятности

С помощью команды `pt()` определим вероятность того, что случайная величина, взятая из t-распределения, окажется меньше рассчитанной нами t-статистики

```{r}
pt(t_value_lizards, df = 198)
```
### Это "сырая" величина. Её еще нельзя сравнивать с уровнем значимости.

Мы должны либо умножить p.value на 2, либо поделить  $\alpha$ пополам, и только после этого сравнивать их.

```{r}
p.value <- 2 * pt(t_value_lizards, df = 198)
p.value
```

Этот результат совпадает с тем, что рассчитал t-тест


### Вопрос: Вероятность какого события отражает p=`r t_lizards$p.value`?

## Уровень значимости p=`r round(t_lizards$p.value, 4)`

Это вероятность того, что выборки которые мы имеем были получены из одной совокупности.

Иными словами: 

Это НЕ вероятность того, что H0 верна.

Это вероятность того, что в мире, где H0 верна, а длины ящериц из Берлина и Саратова равны, шанс получить эмпирические выборки с такими различиями как у нас, составляет 0.2%.

Кстати, какова разница между средними длинами в наших выборках?


## Допущения (Assumptions) t-критерия

- Независимость выборок друг от друга     
- Нормальное распределение сравниваемых величин   
- Равенство дисперсий (можно нарушать, требуется коррекция по методу Велча)  

## Задание

Файл `2.2_aml.csv` содержит данные о влиянии регулярной химиотерапии на продолжительность ремиссии.

Прочитаем эти данные
```{r}
rem <- read.csv("data/2.2_aml.csv", header = T)
str(rem)
```

- В переменной `time` представлена продолжительность ремиссии в днях.
- `group` указывает, к какой экспериментальной группе принадлежал пациент. В группе 1 проводилась регулярная химиотерапия, в группе 2 - нет.

Ваша задача сравнить эти группы с помощью t-теста.

## Решение

```{r purl=FALSE}
t.test (data = valid, time ~ group)
```

Или так:

```{r purl=FALSE, results="hide"}
t.test (valid$time[valid$group==1], valid$time[valid$group==2])
```

# Напоследок

## Статистическая значимость

Статистическая значимость бывает только одна и она говорит о том, в каких отношениях состоят обнаруженные нами эмпирически различия с $\alpha$.

Если мы отвергаем H0, имеются различия.

Если мы не отвергаем H0, все одинаково. 

Пожалуйста, никаких недостоверных различий! Если различия есть, то они достоверны. Если различия не достоверны, то их нет.

А что делать, если сердцем чувствуешь, что что-то должно быть, но тест не дает нужного ответа? Собрать выборки побольше, и посчитать заново. С уже проведенным тестом спорить не надо.
